{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Cognitive Services Personalizer \nhttps://github.com/Azure-Samples/cognitive-services-personalizer-samples"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "In this example, we will use Azure Personalizer Service to predict what Coffee a person (Alice, Bob, Cathy and Dave) prefers given the weather condition and time of day. File \"example.json\" contains their preferred choices of Coffee (set deterministically for the simplicity of this example). We will compare this data with the predictions from the service and generate rewards (0 or 1) based on the match and send it back to the service for training the model.\n\nNote that a model is exported every 5 minutes (current default) if you are using the Cognitive Services instance of the Personalizer service, so you need to wait at least until that time has expired then to actually observe some learning in the rewards returned. Exploration is set at 20%.\n\nCurrent implementation calls the Personalizer service through http calls. We will replace this with a python client in the future."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "!pip install azure-cognitiveservices-personalizer",
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azure.cognitiveservices.personalizer import PersonalizerClient\nfrom azure.cognitiveservices.personalizer.models import RankableAction, RewardRequest, RankRequest\nfrom msrest.authentication import CognitiveServicesCredentials\n\nimport json\nimport matplotlib.pyplot as plt\nimport random \nimport time\nimport uuid",
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "## CONSTANTS\n\n# initialize time\nrandom.seed(time.time())\n\n## total number of requests\nnum_requests = 10000\n\n## pause after N events - for model update frequency \nn_events_per_training = 500\n\n## time in seconds for model update frequency to catch up\nmodel_update_frequency = 70\n\n## sampling rate for recommendations\nsampling_rate = 10\n\n# user and context arrays to pull from randomly\nnamesopt = ['Alice', 'Bob', 'Cathy', 'Dave']\nweatheropt = ['Sunny', 'Rainy', 'Snowy']\ntimeofdayopt = ['Morning', 'Afternoon', 'Evening']\n\n# data files\nexamplepath = \"example.json\"\nrequestpath = \"rankrequest.json\"\nactionfeaturespath = \"actionfeatures.json\"\n\n# Replace 'personalizer_endpoint' and 'personalizer_key' with your valid endpoint values.\npersonalizer_endpoint = \"https://westus2.cognitiveservices.azure.com\"\npersonalizer_key = \"123456789\"",
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "## VARIABLES\n\nuserpref = None \nrankactionsjsonobj = None \nactionfeaturesobj = None\n\ni = 1\nrecommendations = 0\nreward = 0\nrewards = []\ncount = []",
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# SDK - client to Personalizer SDK, authenticated with endpoint and key\nclient = PersonalizerClient(personalizer_endpoint, CognitiveServicesCredentials(personalizer_key))",
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true
      },
      "cell_type": "code",
      "source": "#import data\n\nwith open(examplepath) as handle:\n    userpref = json.loads(handle.read())\n\nwith open(requestpath) as handle:\n    rankactionsjsonobj = json.loads(handle.read())  \n    \nwith open(actionfeaturespath) as handle:\n    actionfeaturesobj = json.loads(handle.read())  \n",
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# pull random user and context features (read early from contextfeatures.json)\ndef add_random_user_and_contextfeatures(namesoption, weatheropt, timeofdayopt):   \n    name = namesopt[random.randint(0,3)]\n    weather = weatheropt[random.randint(0,2)]\n    timeofday = timeofdayopt[random.randint(0,2)]\n    return [name, weather, timeofday]",
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# create unique event id\n# if you don't create one, it is created for you in the rank call\ndef add_event_id():\n    \n    # eventid is a GUID - random, unique value\n    return str(uuid.uuid4())",
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "def exclude_rank_actions():\n    \n    # replace with business logic to determine what to exclude\n    # return array of action IDs\n    return ['Iced mocha']",
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# determine reward\ndef get_reward_from_simulated_data(name, weather, timeofday, prediction):\n    if(userpref[name][weather][timeofday] == str(prediction)):\n        return 1 \n    return 0",
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# parse JSON (read early from actionfeatures.json) to create RankableAction\ndef add_action_features():\n\n    actions = []\n\n    for action in actionfeaturesobj:\n        \n        # SDK - create rankable action\n        rankableActon = RankableAction(id=action[\"id\"], features=action[\"features\"])\n        \n        actions.append(rankableActon) \n\n    return actions",
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "## LOOP - similuates traffic to your Personalizer loop\n\nwhile(i <= num_requests):\n      \n    # reset reward to 0\n    reward = 0\n        \n    #create unique id to associate with an event\n    event_id = add_event_id()\n    \n    #generate a random sample, such as ['Bob', 'Snowy', 'Afternoon']\n    [name, weather, timeofday] = add_random_user_and_contextfeatures(namesopt, weatheropt, timeofdayopt)\n    \n    #put context and environment features in JSON format SDK expects\n    context_features = [{'timeofday': timeofday, 'weather': weather, 'name': name}]\n    \n    print(context_features)\n    \n    # get entire list of rankableActions \n    rankableActions = add_action_features() \n    \n    # get excluded actions - based on business logic\n    excluded_actions = exclude_rank_actions()\n\n    # SDK - Create RANK request\n    rank_request = RankRequest( actions=rankableActions, context_features=context_features, excluded_actions=excluded_actions, event_id=event_id) \n\n    # SDK - RANK - get prediction for top action\n    response = client.rank(rank_request=rank_request)  \n    rankedList = response.ranking\n    \n    ## get top ranked action's ID, such as 'Cappucino'\n    prediction = response.reward_action_id\n    \n    print(\"prediction \", prediction)\n  \n    ## get list of ranked actions\n    rankedList = response.ranking\n    \n    ## display ranked actions list - uncomment following 2 lines\n    #for ranked in rankedList:\n    #    print(ranked.id, ':',ranked.probability)\n        \n    #compare personalization service recommendation with the simulated data to generate a reward value\n    reward = get_reward_from_simulated_data(name, weather, timeofday, prediction)\n    print(\"reward \", reward)      \n       \n    # SDK - REWARD - send the reward to the service \n    client.events.reward(event_id=event_id, value=reward)\n    \n    # total correct recommendations \n    recommendations = recommendations + reward\n    print(\"recommendations \", recommendations)\n    \n    #wait for model_update_frequency before sending more events to observe learning in the next batch\n    if(i % n_events_per_training == 0):\n        print(\"waiting for training frequency...\")\n        time.sleep(model_update_frequency + 5) \n               \n    if(i % sampling_rate == 0):\n        print(\"add recommendations to rewards...\")\n        rewards.append(recommendations)\n        count.append(i)\n        recommendations = 0\n        \n    i = i + 1\n    print(i)\n    \nprint(\"done with sampling\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Plot total number of correct recommendations for every batch of 10 events."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "plt.plot(count, rewards)\nplt.xlabel(\"Batch of rank events\")\nplt.ylabel(\"Correct recommendations per batch\")\nplt.show()",
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "From the above plot, you can observe that the ranking gets better after ~2000 events and performs well over ~80% of the time. Since, the exploration is set to 20%, 20% of the time the system still tries to explore the other options. See https://docs.microsoft.com/en-us/azure/cognitive-services/personalizer/ for more documentation."
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}